# -*- coding: utf-8 -*-
"""DATA_new_aug.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U-6QmXnRoj2bAR41sYUu4w93uEt5_kXD
"""

# !pip install googletrans==3.1.0a0;

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

# WITH_TRANSLATE, DROP_LABELS, WITH_DROP_OVER = True, False, False 

# WITH_TRANSLATE, DROP_LABELS, WITH_DROP_OVER = True, False, False
#
# WITH_TRANSLATE, DROP_LABELS, WITH_DROP_OVER = False, True, False
WITH_TRANSLATE = True
DROP_LABELS = False
WITH_DROP_OVER = True

# WITH_TRANSLATE, DROP_LABELS, WITH_DROP_OVER = False, True, True
# WITH_TRANSLATE, DROP_LABELS, WITH_DROP_OVER = True, True, True
WITH_DEV = False
GE_ONLY = False
DROP_FR = False

ID = "new-aug"
if DROP_FR:
  ID += "-drop-fr"
if WITH_DEV:
  ID += "-with-dev"
if GE_ONLY:
  ID += "-with-ge"
if DROP_LABELS:
  ID += "-drop-labels"
if WITH_DROP_OVER:
  ID += "-drop-over"
if WITH_TRANSLATE:
  ID += "-tra"
ID

data_path = "drive/MyDrive/BERT/new-data"
langs = ['en', 'fr', 'ge', 'it', 'po', 'ru']
mins = [500, 300, 200, 250, 100, 100]
maxs = [500, 800, 750, 300, 200, 200]

lang_dfs = [pd.read_csv(f"drive/MyDrive/BERT/data/original/semeval-{lang}.csv") for lang in langs]
LABEL_COLUMNS = lang_dfs[0].columns[3:]

pd.read_csv(f"drive/MyDrive/BERT/data/original/semeval-en.csv")[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title="Original English Training Dataset", xticks=[0, 500, 1000, 1500, 2000, 2500])

pd.read_csv(f"drive/MyDrive/BERT/data/original/semeval-fr.csv")[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title="fr")

pd.read_csv(f"drive/MyDrive/BERT/data/original/semeval-ge.csv")[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title="ge")

pd.read_csv(f"drive/MyDrive/BERT/data/original/semeval-it.csv")[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title="it")

pd.read_csv(f"drive/MyDrive/BERT/data/original/semeval-po.csv")[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title="po")

pd.read_csv(f"drive/MyDrive/BERT/data/original/semeval-ru.csv")[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title="ru")

# dev_dfs = [pd.read_csv(f"drive/MyDrive/BERT/data/dev-sets/dev-set-{lang}.csv") for lang in langs]
# for lang, dev_df in zip(langs, dev_dfs):
#   print(f'{lang}, {len(dev_df)}')

# lang_with_dev_dfs = [pd.concat([lang_df, dev_df]) for lang_df, dev_df in zip(lang_dfs, dev_dfs)]

# for lang, dffff in zip(langs, lang_with_dev_dfs):
#   print(f'{lang}, {len(dffff)}')

LABEL_COLUMNS = lang_dfs[0].columns[3:]

# for lang, lang_df, lang_with_dev_df in zip(langs, lang_dfs, lang_with_dev_dfs):
#   print(f'{lang}')
#   lang_df[LABEL_COLUMNS].sum().sort_values().plot(kind="barh")
#   plt.show()

#   print(f'with dev {lang}')
#   lang_with_dev_df[LABEL_COLUMNS].sum().sort_values().plot(kind="barh")
#   plt.show()

for lang, df in zip(langs, lang_dfs):
  print(f'{lang}, {len(df)}')

try:
  os.mkdir(f"{data_path}/{ID}")
except:
  pass


try:
  for lang in langs:
    os.mkdir(f"{data_path}/{ID}/{lang}")
except:
  pass

if WITH_DEV:
  print("adding dev")
  lang_dfs = lang_with_dev_dfs

LABEL_COLUMNS = lang_dfs[0].columns[3:]

def find_train_df(curr_lang):
  return [lang_df for lang, lang_df in zip(langs, lang_dfs) if lang == curr_lang][0]

def get_other_lang_dfs(curr_lang):
  if DROP_FR:
    print("taking only german")
    other_langs = [lang_df for lang, lang_df in zip(langs, lang_dfs) if lang != curr_lang and lang != "fr"]
    print("other langs", len(other_langs))
    return other_langs
  else:
    other_langs = [lang_df for lang, lang_df in zip(langs, lang_dfs) if lang != curr_lang]
    print("other langs", len(other_langs))
    return other_langs

def augment_new(curr_lang, min_):
  print(curr_lang)

  curr_df = find_train_df(curr_lang)
  curr_df[LABEL_COLUMNS].sum().sort_values().plot(kind="barh")
  plt.show()

  other_lang_dfs = get_other_lang_dfs(curr_lang)
  
  cols_to_aug = [col for col in LABEL_COLUMNS if curr_df[col].sum() < min_]

  print('cols to aug', cols_to_aug)

  new_df = curr_df.copy()
  print('new df', len(new_df))
  print('new_df.iloc[0].text', new_df.iloc[0].text)

  lang_to_trans = translator.detect(new_df.iloc[0].text).lang
    
  flag = True
  print('pulling from', len(other_lang_dfs), "other langs")
  for other_lang_df in other_lang_dfs:
    
    other_lang_col = other_lang_df[(other_lang_df[cols_to_aug] == 1).any(axis=1)]  

    if flag:
      test = other_lang_col.iloc[0]['text']
      print(test)
      print(translator.translate(test, dest=lang_to_trans).text)
      flag = False

    if WITH_TRANSLATE:
      print('translating', other_lang_col.iloc[0]['text'], "to", lang_to_trans)
      other_lang_col['text'] = other_lang_col['text'].apply(lambda x: translator.translate(x, dest=lang_to_trans).text)

    print('adding', len(other_lang_col), "from", other_lang_col.iloc[0]['text'])
    new_df = pd.concat([new_df, other_lang_col])
    print('new df', len(new_df))

  
  print(f"{curr_lang} new augmented")
  

  return new_df

def under(curr_lang, df_, max_):

  over_reps = [col for col in LABEL_COLUMNS if df_[col].sum() > max_]
  print("dropping single occurrence over reps", over_reps)
  
  print(df_['Whataboutism'].sum())
  under_df = df_[~( (df_[over_reps] == 1).any(1) & (df_[LABEL_COLUMNS].apply(lambda x: sum(x), axis=1) == 1))]
  print(under_df['Whataboutism'].sum())
  
  print(f"{curr_lang} augmented")  
  df_[LABEL_COLUMNS].sum().sort_values().plot(kind="barh")
  plt.show()
  
  print(f"{curr_lang} augmented, under")
  under_df[LABEL_COLUMNS].sum().sort_values().plot(kind="barh")
  plt.show()

  return under_df

# round_1 = zip(langs[:3], mins[:3], maxs[:3])
# round_2 = zip(langs[3:], mins[3:], maxs[3:])

ID

# for lang_to_aug, min__, max__ in round_1:
#   print("augmenting", lang_to_aug)
#   augment_new_df = augment_new(lang_to_aug, min__)
#   under_df = under(lang_to_aug, augment_new_df, max__)
#   under_df[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title=lang_to_aug)


#   path = f"{data_path}/{ID}/{lang_to_aug}"
#   print(f"saving to {path}")
  
#   try:
#     os.mkdir(path)
#   except:
#     pass
  
#   plt.savefig(f"{path}/{ID}-{lang_to_aug}.png", bbox_inches='tight')
#   under_df.to_csv(f"{path}/semeval-{ID}-{lang_to_aug}.csv", index=False)

# for lang_to_aug, min__, max__ in round_2:
#   print("augmenting", lang_to_aug)
#   augment_new_df = augment_new(lang_to_aug, min__)
#   under_df = under(lang_to_aug, augment_new_df, max__)
#   under_df[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title=lang_to_aug)


#   path = f"{data_path}/{ID}/{lang_to_aug}"
#   print(f"saving to {path}")
  
#   try:
#     os.mkdir(path)
#   except:
#     pass
  
#   plt.savefig(f"{path}/{ID}-{lang_to_aug}.png", bbox_inches='tight')
#   under_df.to_csv(f"{path}/semeval-{ID}-{lang_to_aug}.csv", index=False)

for lang_to_aug, min__, max__ in zip([langs[:-1]], [mins[:-1]], [maxs[:-1]]):
  print("augmenting", lang_to_aug)
  print("min", min__)
  print("max", max__)
  augment_new_df = augment_new(lang_to_aug, min__)
  under_df = under(lang_to_aug, augment_new_df, max__)
  under_df[LABEL_COLUMNS].sum().sort_values().plot(kind="barh", title=lang_to_aug)


  path = f"{data_path}/{ID}/{lang_to_aug}"
  print(f"saving to {path}")
  
  try:
    os.mkdir(path)
  except:
    pass
  
  plt.savefig(f"{path}/{ID}-{lang_to_aug}.png", bbox_inches='tight')
  under_df.to_csv(f"{path}/semeval-{ID}-{lang_to_aug}.csv", index=False)

ID

# under_dfs = [under(lang, aug_df, max__) for lang, aug_df, max__ in zip(langs, augment_new_dfs, maxs)]

# augment_new_dfs = [augment_new(lang, min__) for lang, min__ in round_2]

# under_dfs = [under(lang, aug_df, max__) for lang, aug_df, max__ in zip(langs, augment_new_dfs, maxs)]

# for curr_lang, aug_df in zip(langs, augment_new_dfs):
#   print(curr_lang)
#   aug_df[LABEL_COLUMNS].sum().sort_values().plot(kind="barh")
#   plt.savefig(f"{data_path}/{ID}/{ID}-{curr_lang}.png", bbox_inches='tight')
#   plt.show()
#   print(aug_df['Whataboutism'].sum())

# under_dfs = [under(lang, aug_df, max__) for lang, aug_df, max__ in zip(langs, augment_new_dfs, maxs)]

# dfs_to_save = augment_new_dfs
# # if WITH_DROP_OVER:
#   # print("saving drop over")
#   dfs_to_save = under_dfs

# for x, lang_ in zip(dfs_to_save, langs):
#   # x.to_csv(f"{data_path}/{ID}/semeval-{ID}-{lang_}.csv", index=False)

